"""
# ç”¨æˆ·æ€§æ ¼åˆ†ææ’ä»¶ (Personality Analysis)

åŸºäºèŠå¤©è®°å½•åˆ†æç”¨æˆ·æ€§æ ¼ç‰¹å¾ï¼Œç”Ÿæˆè¯¦ç»†çš„æ€§æ ¼åˆ†ææŠ¥å‘Šã€‚

## ä¸»è¦åŠŸèƒ½

- **å¤§äº”äººæ ¼åˆ†æ**: è¯„ä¼°å¼€æ”¾æ€§ã€å°½è´£æ€§ã€å¤–å‘æ€§ã€å®œäººæ€§ã€ç¥ç»è´¨äº”ä¸ªç»´åº¦
- **MBTIåˆ†æ**: åˆ¤æ–­ç”¨æˆ·çš„MBTIäººæ ¼ç±»å‹ï¼ˆ16ç§ç±»å‹ä¹‹ä¸€ï¼‰
- **è¡Œä¸ºæ¨¡å¼è¯†åˆ«**: è¯†åˆ«ç¤¾äº¤ä¹ æƒ¯ã€æ—¶é—´ä¹ æƒ¯ã€è¯­è¨€é£æ ¼ç­‰
- **å¯è§†åŒ–æŠ¥å‘Š**: ç”ŸæˆMarkdownæ ¼å¼çš„è¯¦ç»†åˆ†ææŠ¥å‘Š
- **æ™ºèƒ½ç¼“å­˜**: é¿å…é‡å¤åˆ†æï¼Œæå‡æ•ˆç‡

## ä½¿ç”¨æ–¹æ³•

ç›´æ¥å‘AIè¯·æ±‚åˆ†ææŸä¸ªç”¨æˆ·çš„æ€§æ ¼ï¼ŒAIä¼šè‡ªåŠ¨è°ƒç”¨æ’ä»¶è¿›è¡Œåˆ†æã€‚

## é…ç½®è¯´æ˜

- **åˆ†ææ¨¡å‹ç»„**: ç”¨äºæ€§æ ¼åˆ†æçš„LLMæ¨¡å‹ç»„
- **åˆ†ææ—¶é—´èŒƒå›´**: é»˜è®¤åˆ†ææœ€è¿‘30å¤©çš„èŠå¤©è®°å½•
- **æœ€å¤§æ¶ˆæ¯æ•°**: é»˜è®¤åˆ†ææœ€è¿‘500æ¡æ¶ˆæ¯
- **ç¼“å­˜æœ‰æ•ˆæœŸ**: åˆ†æç»“æœç¼“å­˜7å¤©
"""

import json
import re
import time
from datetime import datetime
from typing import Dict, List, Optional

from pydantic import BaseModel, Field

from nekro_agent.api import core, schemas
from nekro_agent.api.plugin import ConfigBase, NekroPlugin, SandboxMethodType
from nekro_agent.models.db_chat_message import DBChatMessage
from nekro_agent.services.agent.openai import gen_openai_chat_response

plugin = NekroPlugin(
    name="ç”¨æˆ·æ€§æ ¼åˆ†ææ’ä»¶",
    module_name="personality_analysis",
    description="åŸºäºèŠå¤©è®°å½•åˆ†æç”¨æˆ·æ€§æ ¼ç‰¹å¾ï¼Œç”Ÿæˆå¤§äº”äººæ ¼å’ŒMBTIåˆ†ææŠ¥å‘Š",
    version="0.1.0",
    author="A1A7432",
    url="https://github.com/1A7432/nekro-agent-personality-analysis",
    support_adapter=["onebot_v11", "discord", "telegram", "wechatpad", "wxwork"],
)


@plugin.mount_config()
class PersonalityAnalysisConfig(ConfigBase):
    """æ€§æ ¼åˆ†æé…ç½®"""

    DEFAULT_ANALYSIS_DAYS: int = Field(
        default=30,
        title="é»˜è®¤åˆ†ææ—¶é—´èŒƒå›´ï¼ˆå¤©ï¼‰",
        description="åˆ†ææœ€è¿‘å¤šå°‘å¤©çš„èŠå¤©è®°å½•",
    )
    DEFAULT_MAX_MESSAGES: int = Field(
        default=500,
        title="é»˜è®¤æœ€å¤§åˆ†ææ¶ˆæ¯æ•°",
        description="æœ€å¤šåˆ†æå¤šå°‘æ¡æ¶ˆæ¯",
    )
    MIN_MESSAGE_THRESHOLD: int = Field(
        default=50,
        title="æœ€å°æ¶ˆæ¯æ ·æœ¬é‡é˜ˆå€¼",
        description="å°‘äºè¯¥æ•°é‡ä¼šè­¦å‘Šæ ·æœ¬é‡ä¸è¶³",
    )
    CACHE_EXPIRE_DAYS: int = Field(
        default=7,
        title="ç¼“å­˜è¿‡æœŸå¤©æ•°",
        description="åˆ†æç»“æœç¼“å­˜çš„æœ‰æ•ˆæœŸï¼ˆå¤©ï¼‰",
    )
    ENABLE_BIG_FIVE: bool = Field(
        default=True,
        title="å¯ç”¨å¤§äº”äººæ ¼åˆ†æ",
        description="æ˜¯å¦è¿›è¡Œå¤§äº”äººæ ¼è¯„ä¼°",
    )
    ENABLE_MBTI: bool = Field(
        default=True,
        title="å¯ç”¨MBTIåˆ†æ",
        description="æ˜¯å¦è¿›è¡ŒMBTIäººæ ¼ç±»å‹åˆ¤æ–­",
    )
    ENABLE_BEHAVIOR_PATTERN: bool = Field(
        default=True,
        title="å¯ç”¨è¡Œä¸ºæ¨¡å¼è¯†åˆ«",
        description="æ˜¯å¦è¯†åˆ«ç”¨æˆ·çš„è¡Œä¸ºæ¨¡å¼",
    )
    ANALYSIS_MODEL_GROUP: str = Field(
        default="default",
        title="åˆ†ææ¨¡å‹ç»„",
        description="ç”¨äºæ€§æ ¼åˆ†æçš„æ¨¡å‹ç»„åç§°",
        json_schema_extra={"ref_model_groups": True, "required": True, "model_type": "chat"},
    )
    MAX_ANALYSIS_TOKENS: int = Field(
        default=2048,
        title="æœ€å¤§åˆ†æTokenæ•°",
        description="å•æ¬¡åˆ†æçš„æœ€å¤§è¾“å‡ºTokenæ•°ï¼ˆç”¨äºLLMå“åº”ï¼‰",
    )


# è·å–é…ç½®å’Œæ’ä»¶å­˜å‚¨
config: PersonalityAnalysisConfig = plugin.get_config(PersonalityAnalysisConfig)
store = plugin.store


# region: æ•°æ®æ¨¡å‹å®šä¹‰


class BigFiveScore(BaseModel):
    """å¤§äº”äººæ ¼è¯„åˆ†"""

    openness: int = Field(ge=0, le=100, description="å¼€æ”¾æ€§")
    conscientiousness: int = Field(ge=0, le=100, description="å°½è´£æ€§")
    extraversion: int = Field(ge=0, le=100, description="å¤–å‘æ€§")
    agreeableness: int = Field(ge=0, le=100, description="å®œäººæ€§")
    neuroticism: int = Field(ge=0, le=100, description="ç¥ç»è´¨")


class MBTIResult(BaseModel):
    """MBTIåˆ†æç»“æœ"""

    mbti_type: str = Field(description="MBTIç±»å‹ï¼Œå¦‚INFP")
    confidence: float = Field(ge=0, le=1, description="ç½®ä¿¡åº¦")
    dimension_scores: Dict[str, float] = Field(
        description="å„ç»´åº¦å¾—åˆ†ï¼Œå¦‚{'E-I': 0.6, 'S-N': 0.4, 'T-F': 0.7, 'J-P': 0.3}",
    )


class PersonalityAnalysisResult(BaseModel):
    """æ€§æ ¼åˆ†æç»“æœ"""

    target_userid: str
    target_username: str
    analysis_timestamp: int
    message_sample_size: int
    time_range_start: int
    time_range_end: int
    big_five_scores: Optional[BigFiveScore] = None
    mbti_result: Optional[MBTIResult] = None
    personality_summary: str
    behavior_patterns: List[str]
    communication_style: str
    emotional_tendency: str
    report_markdown: str


class MessageStatistics(BaseModel):
    """æ¶ˆæ¯ç»Ÿè®¡ä¿¡æ¯"""

    total_count: int
    avg_length: float
    time_distribution: Dict[str, int]
    emoji_count: int
    mention_count: int
    question_count: int
    positive_count: int
    negative_count: int


# endregion: æ•°æ®æ¨¡å‹å®šä¹‰


# region: æ•°æ®é‡‡é›†æ¨¡å—


async def query_user_messages(
    chat_key: str,
    target_userid: str,
    days: int,
    max_messages: int,
) -> List[DBChatMessage]:
    """æŸ¥è¯¢ç”¨æˆ·å†å²æ¶ˆæ¯"""
    end_time = int(time.time())
    start_time = end_time - (days * 24 * 60 * 60)

    messages = (
        await DBChatMessage.filter(
            chat_key=chat_key,
            platform_userid=target_userid,
            send_timestamp__gte=start_time,
            send_timestamp__lte=end_time,
            is_recalled=False,
        )
        .order_by("-send_timestamp")
        .limit(max_messages)
    )

    filtered_messages = []
    for msg in messages:
        if msg.is_system:
            continue
        if len(msg.content_text.strip()) < 2:
            continue
        filtered_messages.append(msg)

    return filtered_messages


def clean_message_text(text: str) -> str:
    """æ¸…æ´—æ¶ˆæ¯æ–‡æœ¬"""
    text = re.sub(r"\[CQ:.*?\]", "", text)
    text = re.sub(r"\s+", " ", text)
    text = re.sub(r"1[3-9]\d{9}", "[æ‰‹æœºå·]", text)
    text = re.sub(r"\d{17}[\dXx]", "[èº«ä»½è¯]", text)
    return text.strip()


def analyze_message_statistics(messages: List[DBChatMessage]) -> MessageStatistics:
    """åˆ†ææ¶ˆæ¯ç»Ÿè®¡ä¿¡æ¯"""
    if not messages:
        return MessageStatistics(
            total_count=0,
            avg_length=0,
            time_distribution={"morning": 0, "afternoon": 0, "evening": 0, "night": 0},
            emoji_count=0,
            mention_count=0,
            question_count=0,
            positive_count=0,
            negative_count=0,
        )

    total_length = 0
    time_dist = {"morning": 0, "afternoon": 0, "evening": 0, "night": 0}
    emoji_count = 0
    mention_count = 0
    question_count = 0

    for msg in messages:
        total_length += len(msg.content_text)

        hour = datetime.fromtimestamp(msg.send_timestamp).hour
        if 6 <= hour < 12:
            time_dist["morning"] += 1
        elif 12 <= hour < 18:
            time_dist["afternoon"] += 1
        elif 18 <= hour < 23:
            time_dist["evening"] += 1
        else:
            time_dist["night"] += 1

        emoji_pattern = r"[\U0001F300-\U0001F9FF]|[\U0001F600-\U0001F64F]|[\U0001F680-\U0001F6FF]"
        emoji_count += len(re.findall(emoji_pattern, msg.content_text))

        if "[@" in msg.content_text or "@" in msg.content_text:
            mention_count += 1

        if "?" in msg.content_text or "ï¼Ÿ" in msg.content_text:
            question_count += 1

    avg_length = total_length / len(messages) if messages else 0

    return MessageStatistics(
        total_count=len(messages),
        avg_length=avg_length,
        time_distribution=time_dist,
        emoji_count=emoji_count,
        mention_count=mention_count,
        question_count=question_count,
        positive_count=0,
        negative_count=0,
    )


def prepare_analysis_input(messages: List[DBChatMessage], stats: MessageStatistics) -> str:
    """å‡†å¤‡åˆ†æè¾“å…¥æ•°æ®"""
    sample_messages = messages[:100] if len(messages) > 100 else messages

    message_texts = []
    for msg in sample_messages:
        cleaned_text = clean_message_text(msg.content_text)
        if cleaned_text:
            timestamp = datetime.fromtimestamp(msg.send_timestamp).strftime("%H:%M")
            message_texts.append(f"[{timestamp}] {cleaned_text}")

    input_text = "æ¶ˆæ¯æ ·æœ¬ï¼š\n" + "\n".join(message_texts)
    input_text += f"\n\nç»Ÿè®¡ä¿¡æ¯ï¼š\n"
    input_text += f"- æ€»æ¶ˆæ¯æ•°ï¼š{stats.total_count}\n"
    input_text += f"- å¹³å‡æ¶ˆæ¯é•¿åº¦ï¼š{stats.avg_length:.1f}å­—\n"
    input_text += f"- æ—¶é—´åˆ†å¸ƒï¼šæ—©æ™¨{stats.time_distribution['morning']}æ¡ï¼Œä¸‹åˆ{stats.time_distribution['afternoon']}æ¡ï¼Œå‚æ™š{stats.time_distribution['evening']}æ¡ï¼Œå¤œæ™š{stats.time_distribution['night']}æ¡\n"
    input_text += f"- è¡¨æƒ…ç¬¦å·ä½¿ç”¨ï¼š{stats.emoji_count}æ¬¡\n"
    input_text += f"- @ä»–äººé¢‘ç‡ï¼š{stats.mention_count}æ¬¡\n"
    input_text += f"- æé—®é¢‘ç‡ï¼š{stats.question_count}æ¬¡\n"

    return input_text


# endregion: æ•°æ®é‡‡é›†æ¨¡å—


# region: æ€§æ ¼åˆ†æå¼•æ“


async def analyze_big_five_personality(input_data: str) -> BigFiveScore:
    """å¤§äº”äººæ ¼åˆ†æ"""
    prompt = f"""ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„å¿ƒç†å­¦ä¸“å®¶ï¼Œä¸“ç²¾äºåŸºäºæ–‡æœ¬è¡Œä¸ºåˆ†æè¿›è¡Œå¤§äº”äººæ ¼è¯„ä¼°ã€‚

è¯·åŸºäºä»¥ä¸‹èŠå¤©æ¶ˆæ¯æ ·æœ¬å’Œç»Ÿè®¡ä¿¡æ¯ï¼Œåˆ†æç”¨æˆ·åœ¨å¤§äº”äººæ ¼å„ç»´åº¦çš„å¾—åˆ†ï¼ˆ0-100åˆ†ï¼‰ï¼š

1. å¼€æ”¾æ€§ï¼ˆOpennessï¼‰ï¼šå¯¹æ–°ä½“éªŒçš„æ¥å—ç¨‹åº¦ï¼Œåˆ›é€ æ€§ï¼Œå¥½å¥‡å¿ƒ
2. å°½è´£æ€§ï¼ˆConscientiousnessï¼‰ï¼šç»„ç»‡æ€§ï¼Œå¯é æ€§ï¼Œè‡ªå¾‹æ€§
3. å¤–å‘æ€§ï¼ˆExtraversionï¼‰ï¼šç¤¾äº¤æ€§ï¼Œæ´»åŠ›ï¼Œä¸»åŠ¨æ€§
4. å®œäººæ€§ï¼ˆAgreeablenessï¼‰ï¼šåˆä½œæ€§ï¼ŒåŒç†å¿ƒï¼Œå‹å–„æ€§
5. ç¥ç»è´¨ï¼ˆNeuroticismï¼‰ï¼šæƒ…ç»ªç¨³å®šæ€§ï¼ˆåˆ†æ•°è¶Šé«˜è¶Šä¸ç¨³å®šï¼‰

{input_data}

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼ˆä»…è¾“å‡ºJSONï¼Œä¸è¦ä»»ä½•å…¶ä»–å†…å®¹ï¼‰ï¼š
{{
    "openness": æ•´æ•°ï¼ˆ0-100ï¼‰,
    "conscientiousness": æ•´æ•°ï¼ˆ0-100ï¼‰,
    "extraversion": æ•´æ•°ï¼ˆ0-100ï¼‰,
    "agreeableness": æ•´æ•°ï¼ˆ0-100ï¼‰,
    "neuroticism": æ•´æ•°ï¼ˆ0-100ï¼‰,
    "reasoning": "ç®€è¦è¯´æ˜è¯„åˆ†ç†ç”±"
}}"""

    try:
        model_group = core.config.get_model_group_info(config.ANALYSIS_MODEL_GROUP)
        response = await gen_openai_chat_response(
            model=model_group.CHAT_MODEL,
            messages=[{"role": "user", "content": prompt}],
            base_url=model_group.BASE_URL,
            api_key=model_group.API_KEY,
            temperature=0.3,
            max_tokens=1024,
        )

        content = response.response_content.strip()
        if not content:
            core.logger.warning("å¤§äº”äººæ ¼åˆ†æè¿”å›å†…å®¹ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤å€¼")
            return BigFiveScore(
                openness=50,
                conscientiousness=50,
                extraversion=50,
                agreeableness=50,
                neuroticism=50,
            )

        json_match = re.search(r"\{.*\}", content, re.DOTALL)
        if json_match:
            content = json_match.group()

        result = json.loads(content)
        return BigFiveScore(
            openness=result["openness"],
            conscientiousness=result["conscientiousness"],
            extraversion=result["extraversion"],
            agreeableness=result["agreeableness"],
            neuroticism=result["neuroticism"],
        )
    except Exception as e:
        core.logger.error(f"å¤§äº”äººæ ¼åˆ†æå¤±è´¥: {e}")
        return BigFiveScore(
            openness=50,
            conscientiousness=50,
            extraversion=50,
            agreeableness=50,
            neuroticism=50,
        )


async def analyze_mbti_type(input_data: str) -> MBTIResult:
    """MBTIåˆ†æ"""
    prompt = f"""ä½ æ˜¯ä¸€ä½MBTIè®¤è¯åˆ†æå¸ˆï¼Œæ“…é•¿ä»è¡Œä¸ºæ¨¡å¼è¯†åˆ«äººæ ¼ç±»å‹ã€‚

è¯·æ ¹æ®ç”¨æˆ·çš„èŠå¤©è¡Œä¸ºå’Œè¯­è¨€é£æ ¼ï¼Œåˆ¤æ–­å…¶åœ¨MBTIå››ä¸ªç»´åº¦ä¸Šçš„å€¾å‘ï¼š

1. Eï¼ˆå¤–å‘ï¼‰vs Iï¼ˆå†…å‘ï¼‰ï¼šèƒ½é‡æ¥æº
2. Sï¼ˆæ„Ÿè§‰ï¼‰vs Nï¼ˆç›´è§‰ï¼‰ï¼šä¿¡æ¯å¤„ç†
3. Tï¼ˆæ€è€ƒï¼‰vs Fï¼ˆæƒ…æ„Ÿï¼‰ï¼šå†³ç­–æ–¹å¼
4. Jï¼ˆåˆ¤æ–­ï¼‰vs Pï¼ˆçŸ¥è§‰ï¼‰ï¼šç”Ÿæ´»æ€åº¦

{input_data}

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼ˆä»…è¾“å‡ºJSONï¼Œä¸è¦ä»»ä½•å…¶ä»–å†…å®¹ï¼‰ï¼š
{{
    "mbti_type": "å››ä¸ªå­—æ¯çš„MBTIç±»å‹ï¼ˆå¦‚INFPï¼‰",
    "confidence": 0.0åˆ°1.0ä¹‹é—´çš„å°æ•°,
    "dimension_scores": {{
        "E-I": 0.0åˆ°1.0ï¼ˆè¶Šæ¥è¿‘0è¶ŠIï¼Œè¶Šæ¥è¿‘1è¶ŠEï¼‰,
        "S-N": 0.0åˆ°1.0ï¼ˆè¶Šæ¥è¿‘0è¶ŠSï¼Œè¶Šæ¥è¿‘1è¶ŠNï¼‰,
        "T-F": 0.0åˆ°1.0ï¼ˆè¶Šæ¥è¿‘0è¶ŠTï¼Œè¶Šæ¥è¿‘1è¶ŠFï¼‰,
        "J-P": 0.0åˆ°1.0ï¼ˆè¶Šæ¥è¿‘0è¶ŠJï¼Œè¶Šæ¥è¿‘1è¶ŠPï¼‰
    }},
    "reasoning": "ç®€è¦è¯´æ˜åˆ¤æ–­ç†ç”±"
}}"""

    try:
        model_group = core.config.get_model_group_info(config.ANALYSIS_MODEL_GROUP)
        response = await gen_openai_chat_response(
            model=model_group.CHAT_MODEL,
            messages=[{"role": "user", "content": prompt}],
            base_url=model_group.BASE_URL,
            api_key=model_group.API_KEY,
            temperature=0.3,
            max_tokens=1024,
        )

        content = response.response_content.strip()
        if not content:
            core.logger.warning("MBTIåˆ†æè¿”å›å†…å®¹ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤å€¼")
            return MBTIResult(
                mbti_type="XXXX",
                confidence=0.5,
                dimension_scores={"E-I": 0.5, "S-N": 0.5, "T-F": 0.5, "J-P": 0.5},
            )

        json_match = re.search(r"\{.*\}", content, re.DOTALL)
        if json_match:
            content = json_match.group()

        result = json.loads(content)
        return MBTIResult(
            mbti_type=result["mbti_type"],
            confidence=result["confidence"],
            dimension_scores=result["dimension_scores"],
        )
    except Exception as e:
        core.logger.error(f"MBTIåˆ†æå¤±è´¥: {e}")
        return MBTIResult(
            mbti_type="XXXX",
            confidence=0.5,
            dimension_scores={"E-I": 0.5, "S-N": 0.5, "T-F": 0.5, "J-P": 0.5},
        )


async def identify_behavior_patterns(input_data: str, stats: MessageStatistics) -> List[str]:
    """è¯†åˆ«è¡Œä¸ºæ¨¡å¼"""
    patterns = []

    max_time = max(stats.time_distribution, key=stats.time_distribution.get)
    time_patterns = {
        "morning": "æ—©èµ·é¸Ÿï¼ˆç»å¸¸åœ¨æ—©æ™¨æ´»è·ƒï¼‰",
        "afternoon": "åˆé—´æ´»è·ƒè€…ï¼ˆä¸‹åˆæ—¶æ®µæœ€ä¸ºæ´»è·ƒï¼‰",
        "evening": "å‚æ™šæ—¶æ®µæ´»è·ƒ",
        "night": "å¤œçŒ«å­ï¼ˆæ·±å¤œæ—¶æ®µæ´»è·ƒï¼‰",
    }
    patterns.append(time_patterns.get(max_time, "æ—¶é—´ä¹ æƒ¯ä¸æ˜æ˜¾"))

    if stats.mention_count > stats.total_count * 0.3:
        patterns.append("é«˜é¢‘äº’åŠ¨è€…ï¼ˆå–œæ¬¢@ä»–äººï¼‰")
    elif stats.mention_count < stats.total_count * 0.1:
        patterns.append("ç‹¬ç«‹è¡¨è¾¾è€…ï¼ˆè¾ƒå°‘@ä»–äººï¼‰")

    if stats.emoji_count > stats.total_count * 0.5:
        patterns.append("emojiçˆ±å¥½è€…ï¼ˆé¢‘ç¹ä½¿ç”¨è¡¨æƒ…ç¬¦å·ï¼‰")
    elif stats.emoji_count < stats.total_count * 0.1:
        patterns.append("çº¯æ–‡æœ¬æ´¾ï¼ˆå¾ˆå°‘ä½¿ç”¨è¡¨æƒ…ï¼‰")

    if stats.avg_length > 50:
        patterns.append("è¯¦ç»†è¡¨è¾¾è€…ï¼ˆæ¶ˆæ¯é€šå¸¸è¾ƒé•¿ï¼‰")
    elif stats.avg_length < 15:
        patterns.append("ç®€æ´æ´¾ï¼ˆæ¶ˆæ¯ç®€çŸ­ç²¾ç‚¼ï¼‰")

    if stats.question_count > stats.total_count * 0.3:
        patterns.append("å¥½å¥‡æé—®è€…ï¼ˆç»å¸¸æå‡ºé—®é¢˜ï¼‰")

    return patterns


# endregion: æ€§æ ¼åˆ†æå¼•æ“


# region: æŠ¥å‘Šç”Ÿæˆæ¨¡å—


def generate_progress_bar(score: int, max_length: int = 10) -> str:
    """ç”Ÿæˆæ–‡æœ¬è¿›åº¦æ¡"""
    filled = int(score / 10)
    bar = "â–ˆ" * filled + "â–‘" * (max_length - filled)
    return f"{bar} {score}/100"


def get_mbti_description(mbti_type: str) -> str:
    """è·å–MBTIç±»å‹æè¿°"""
    descriptions = {
        "INTJ": "å»ºç­‘å¸ˆå‹ - å¯Œæœ‰æƒ³è±¡åŠ›å’Œæˆ˜ç•¥æ€§çš„æ€æƒ³å®¶",
        "INTP": "é€»è¾‘å­¦å®¶å‹ - å…·æœ‰åˆ›æ–°ç²¾ç¥çš„å‘æ˜å®¶",
        "ENTJ": "æŒ‡æŒ¥å®˜å‹ - å¤§èƒ†ã€å¯Œæœ‰æƒ³è±¡åŠ›çš„å¼ºå¤§é¢†å¯¼è€…",
        "ENTP": "è¾©è®ºå®¶å‹ - èªæ˜å¥½å¥‡çš„æ€æƒ³å®¶",
        "INFJ": "æå€¡è€…å‹ - å®‰é™è€Œç¥ç§˜çš„ç†æƒ³ä¸»ä¹‰è€…",
        "INFP": "è°ƒåœè€…å‹ - è¯—æ„ã€å–„è‰¯çš„åˆ©ä»–ä¸»ä¹‰è€…",
        "ENFJ": "ä¸»äººå…¬å‹ - å¯Œæœ‰é­…åŠ›ã€é¼“èˆäººå¿ƒçš„é¢†å¯¼è€…",
        "ENFP": "ç«é€‰è€…å‹ - çƒ­æƒ…ã€æœ‰åˆ›é€ åŠ›çš„ç¤¾äº¤è€…",
        "ISTJ": "ç‰©æµå¸ˆå‹ - å®ç”¨ã€æ³¨é‡äº‹å®çš„å¯é è€…",
        "ISFJ": "å®ˆå«è€…å‹ - éå¸¸ä¸“æ³¨ã€æ¸©æš–çš„ä¿æŠ¤è€…",
        "ESTJ": "æ€»ç»ç†å‹ - å‡ºè‰²çš„ç®¡ç†è€…",
        "ESFJ": "æ‰§æ”¿å®˜å‹ - ææœ‰åŒæƒ…å¿ƒã€å—æ¬¢è¿çš„äºº",
        "ISTP": "é‰´èµå®¶å‹ - å¤§èƒ†è€Œå®é™…çš„å®éªŒè€…",
        "ISFP": "æ¢é™©å®¶å‹ - çµæ´»ã€æœ‰é­…åŠ›çš„è‰ºæœ¯å®¶",
        "ESTP": "ä¼ä¸šå®¶å‹ - ç²¾æ˜ã€å–„äºæ„ŸçŸ¥çš„å®å¹²è€…",
        "ESFP": "è¡¨æ¼”è€…å‹ - è‡ªå‘çš„ã€å……æ»¡æ´»åŠ›çš„è¡¨æ¼”è€…",
    }
    return descriptions.get(mbti_type, "æœªçŸ¥ç±»å‹")


def generate_markdown_report(result: PersonalityAnalysisResult) -> str:
    """ç”ŸæˆMarkdownæ ¼å¼æŠ¥å‘Š"""
    lines = []

    lines.append(f"# ğŸ“Š ç”¨æˆ·æ€§æ ¼åˆ†ææŠ¥å‘Š")
    lines.append("")
    lines.append(f"**åˆ†æå¯¹è±¡**: {result.target_username}")
    lines.append(f"**åˆ†ææ—¶é—´**: {datetime.fromtimestamp(result.analysis_timestamp).strftime('%Y-%m-%d %H:%M:%S')}")
    lines.append(
        f"**æ•°æ®èŒƒå›´**: {datetime.fromtimestamp(result.time_range_start).strftime('%Y-%m-%d')} è‡³ {datetime.fromtimestamp(result.time_range_end).strftime('%Y-%m-%d')}",
    )
    lines.append(f"**æ ·æœ¬é‡**: {result.message_sample_size} æ¡æ¶ˆæ¯")
    lines.append("")
    lines.append("---")
    lines.append("")

    if result.big_five_scores:
        lines.append("## ğŸ¯ å¤§äº”äººæ ¼è¯„ä¼°")
        lines.append("")
        scores = result.big_five_scores
        lines.append(f"**å¼€æ”¾æ€§ (Openness)**")
        lines.append(f"{generate_progress_bar(scores.openness)}")
        lines.append(f"å¯¹æ–°ä½“éªŒçš„æ¥å—ç¨‹åº¦ã€åˆ›é€ æ€§ã€å¥½å¥‡å¿ƒ")
        lines.append("")

        lines.append(f"**å°½è´£æ€§ (Conscientiousness)**")
        lines.append(f"{generate_progress_bar(scores.conscientiousness)}")
        lines.append(f"ç»„ç»‡æ€§ã€å¯é æ€§ã€è‡ªå¾‹æ€§")
        lines.append("")

        lines.append(f"**å¤–å‘æ€§ (Extraversion)**")
        lines.append(f"{generate_progress_bar(scores.extraversion)}")
        lines.append(f"ç¤¾äº¤æ€§ã€æ´»åŠ›ã€ä¸»åŠ¨æ€§")
        lines.append("")

        lines.append(f"**å®œäººæ€§ (Agreeableness)**")
        lines.append(f"{generate_progress_bar(scores.agreeableness)}")
        lines.append(f"åˆä½œæ€§ã€åŒç†å¿ƒã€å‹å–„æ€§")
        lines.append("")

        lines.append(f"**ç¥ç»è´¨ (Neuroticism)**")
        lines.append(f"{generate_progress_bar(scores.neuroticism)}")
        lines.append(f"æƒ…ç»ªç¨³å®šæ€§ï¼ˆåˆ†æ•°è¶Šä½è¶Šç¨³å®šï¼‰")
        lines.append("")
        lines.append("---")
        lines.append("")

    if result.mbti_result and result.mbti_result.mbti_type != "XXXX":
        lines.append("## ğŸ§© MBTIäººæ ¼ç±»å‹")
        lines.append("")
        mbti = result.mbti_result
        lines.append(f"**ç±»å‹**: **{mbti.mbti_type}** - {get_mbti_description(mbti.mbti_type)}")
        lines.append(f"**ç½®ä¿¡åº¦**: {mbti.confidence * 100:.1f}%")
        lines.append("")

        lines.append("**å„ç»´åº¦å€¾å‘**:")
        dims = mbti.dimension_scores
        ei_label = "å¤–å‘(E)" if dims.get("E-I", 0.5) > 0.5 else "å†…å‘(I)"
        sn_label = "ç›´è§‰(N)" if dims.get("S-N", 0.5) > 0.5 else "æ„Ÿè§‰(S)"
        tf_label = "æƒ…æ„Ÿ(F)" if dims.get("T-F", 0.5) > 0.5 else "æ€è€ƒ(T)"
        jp_label = "çŸ¥è§‰(P)" if dims.get("J-P", 0.5) > 0.5 else "åˆ¤æ–­(J)"

        lines.append(f"- èƒ½é‡æ¥æº: {ei_label} ({dims.get('E-I', 0.5) * 100:.0f}%)")
        lines.append(f"- ä¿¡æ¯å¤„ç†: {sn_label} ({dims.get('S-N', 0.5) * 100:.0f}%)")
        lines.append(f"- å†³ç­–æ–¹å¼: {tf_label} ({dims.get('T-F', 0.5) * 100:.0f}%)")
        lines.append(f"- ç”Ÿæ´»æ€åº¦: {jp_label} ({dims.get('J-P', 0.5) * 100:.0f}%)")
        lines.append("")
        lines.append("---")
        lines.append("")

    if result.behavior_patterns:
        lines.append("## ğŸ” è¡Œä¸ºæ¨¡å¼æ´å¯Ÿ")
        lines.append("")
        for pattern in result.behavior_patterns:
            lines.append(f"- {pattern}")
        lines.append("")
        lines.append("---")
        lines.append("")

    lines.append("## ğŸ’¬ æ²Ÿé€šé£æ ¼")
    lines.append("")
    lines.append(result.communication_style)
    lines.append("")
    lines.append("---")
    lines.append("")

    lines.append("## ğŸ˜Š æƒ…æ„Ÿå€¾å‘")
    lines.append("")
    lines.append(result.emotional_tendency)
    lines.append("")
    lines.append("---")
    lines.append("")

    lines.append("## ğŸ¨ ç»¼åˆæ€§æ ¼ç”»åƒ")
    lines.append("")
    lines.append(result.personality_summary)
    lines.append("")

    lines.append("---")
    lines.append("")
    lines.append("> âš ï¸ **å…è´£å£°æ˜**: æœ¬æŠ¥å‘ŠåŸºäºèŠå¤©è®°å½•çš„AIåˆ†æç”Ÿæˆï¼Œä»…ä¾›å¨±ä¹å‚è€ƒï¼Œä¸æ„æˆä¸“ä¸šå¿ƒç†è¯„ä¼°ã€‚")

    return "\n".join(lines)


# endregion: æŠ¥å‘Šç”Ÿæˆæ¨¡å—


# region: ç¼“å­˜ç®¡ç†æ¨¡å—


async def get_cached_result(chat_key: str, target_userid: str) -> Optional[PersonalityAnalysisResult]:
    """è·å–ç¼“å­˜çš„åˆ†æç»“æœ"""
    cache_key = f"analysis_{target_userid}_{chat_key}"
    cached_data = await store.get(store_key=cache_key)

    if not cached_data:
        return None

    try:
        result = PersonalityAnalysisResult.model_validate_json(cached_data)
        cache_expire_seconds = config.CACHE_EXPIRE_DAYS * 24 * 60 * 60
        if time.time() - result.analysis_timestamp > cache_expire_seconds:
            core.logger.info(f"ç¼“å­˜å·²è¿‡æœŸ: {cache_key}")
            return None
        return result
    except Exception as e:
        core.logger.error(f"è§£æç¼“å­˜æ•°æ®å¤±è´¥: {e}")
        return None


async def save_result_to_cache(chat_key: str, target_userid: str, result: PersonalityAnalysisResult):
    """ä¿å­˜åˆ†æç»“æœåˆ°ç¼“å­˜"""
    cache_key = f"analysis_{target_userid}_{chat_key}"
    await store.set(store_key=cache_key, value=result.model_dump_json())
    core.logger.info(f"å·²ç¼“å­˜åˆ†æç»“æœ: {cache_key}")


async def clear_cache(chat_key: str, target_userid: str):
    """æ¸…é™¤ç¼“å­˜"""
    cache_key = f"analysis_{target_userid}_{chat_key}"
    await store.delete(store_key=cache_key)
    core.logger.info(f"å·²æ¸…é™¤ç¼“å­˜: {cache_key}")


# endregion: ç¼“å­˜ç®¡ç†æ¨¡å—


# region: æ²™ç›’æ–¹æ³•


@plugin.mount_sandbox_method(
    SandboxMethodType.AGENT,
    name="åˆ†æç”¨æˆ·æ€§æ ¼",
    description="åˆ†ææŒ‡å®šç”¨æˆ·çš„æ€§æ ¼ç‰¹å¾å¹¶ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š",
)
async def analyze_user_personality(
    _ctx: schemas.AgentCtx,
    chat_key: str,
    target_userid: str,
    days: int,
    max_messages: int,
    force_refresh: bool,
) -> str:
    """Analyze User Personality (åˆ†æç”¨æˆ·æ€§æ ¼)

    Analyze a user's personality based on their chat history and generate a detailed report.

    Args:
        chat_key (str): Chat channel identifier (use _ck in sandbox)
        target_userid (str): Target user's platform ID
        days (int): Analysis time range in days (e.g., 30 for last 30 days)
        max_messages (int): Maximum number of messages to analyze (e.g., 500)
        force_refresh (bool): Whether to force refresh cache and reanalyze

    Returns:
        str: Markdown formatted personality analysis report

    Example:
        analyze_user_personality(_ck, "user_12345", 30, 500, False)
    """
    if not target_userid:
        raise ValueError("Error: Target user ID cannot be empty!")

    if days < 1 or days > 365:
        raise ValueError("Error: Days must be between 1 and 365!")

    if max_messages < config.MIN_MESSAGE_THRESHOLD or max_messages > 5000:
        raise ValueError(f"Error: Max messages must be between {config.MIN_MESSAGE_THRESHOLD} and 5000!")

    if not force_refresh:
        cached_result = await get_cached_result(chat_key, target_userid)
        if cached_result:
            core.logger.info(f"ä½¿ç”¨ç¼“å­˜çš„åˆ†æç»“æœ: {target_userid}")
            return cached_result.report_markdown

    core.logger.info(f"å¼€å§‹åˆ†æç”¨æˆ·æ€§æ ¼: {target_userid}, æ—¶é—´èŒƒå›´: {days}å¤©, æœ€å¤§æ¶ˆæ¯æ•°: {max_messages}")
    messages = await query_user_messages(chat_key, target_userid, days, max_messages)

    if not messages:
        raise ValueError(f"Error: No chat messages found for user {target_userid} in the last {days} days!")

    if len(messages) < config.MIN_MESSAGE_THRESHOLD:
        core.logger.warning(f"æ¶ˆæ¯æ ·æœ¬é‡ä¸è¶³: {len(messages)} < {config.MIN_MESSAGE_THRESHOLD}")

    stats = analyze_message_statistics(messages)
    input_data = prepare_analysis_input(messages, stats)

    big_five_scores = None
    mbti_result = None

    if config.ENABLE_BIG_FIVE:
        core.logger.info("æ‰§è¡Œå¤§äº”äººæ ¼åˆ†æ...")
        big_five_scores = await analyze_big_five_personality(input_data)

    if config.ENABLE_MBTI:
        core.logger.info("æ‰§è¡ŒMBTIåˆ†æ...")
        mbti_result = await analyze_mbti_type(input_data)

    behavior_patterns = []
    if config.ENABLE_BEHAVIOR_PATTERN:
        core.logger.info("è¯†åˆ«è¡Œä¸ºæ¨¡å¼...")
        behavior_patterns = await identify_behavior_patterns(input_data, stats)

    username = messages[0].sender_nickname if messages else "æœªçŸ¥ç”¨æˆ·"

    communication_style = "è¯¥ç”¨æˆ·çš„æ²Ÿé€šé£æ ¼è¡¨ç°ä¸ºï¼š"
    if stats.avg_length > 50:
        communication_style += "å–œæ¬¢è¯¦ç»†è¡¨è¾¾ï¼Œæ¶ˆæ¯å†…å®¹ä¸°å¯Œï¼›"
    else:
        communication_style += "å€¾å‘ç®€æ´æ²Ÿé€šï¼Œè¨€ç®€æ„èµ…ï¼›"

    if stats.emoji_count > stats.total_count * 0.3:
        communication_style += "é¢‘ç¹ä½¿ç”¨è¡¨æƒ…ç¬¦å·å¢å¼ºè¡¨è¾¾ï¼›"

    if stats.mention_count > stats.total_count * 0.2:
        communication_style += "ä¸»åŠ¨ä¸ä»–äººäº’åŠ¨ï¼Œå–œæ¬¢@æåŠä»–äººã€‚"

    emotional_tendency = "ä»æƒ…æ„Ÿè¡¨è¾¾æ¥çœ‹ï¼Œ"
    if big_five_scores and big_five_scores.neuroticism < 40:
        emotional_tendency += "è¯¥ç”¨æˆ·æƒ…ç»ªè¾ƒä¸ºç¨³å®šï¼Œè¡¨ç°å‡ºè‰¯å¥½çš„å¿ƒç†éŸ§æ€§ã€‚"
    elif big_five_scores and big_five_scores.neuroticism > 60:
        emotional_tendency += "è¯¥ç”¨æˆ·æƒ…æ„Ÿè¡¨è¾¾è¾ƒä¸ºä¸°å¯Œï¼Œæœ‰æ—¶ä¼šè¡¨ç°å‡ºæƒ…ç»ªæ³¢åŠ¨ã€‚"
    else:
        emotional_tendency += "è¯¥ç”¨æˆ·çš„æƒ…æ„Ÿè¡¨è¾¾å¤„äºæ­£å¸¸èŒƒå›´ã€‚"

    personality_summary = f"ç»¼åˆæ¥çœ‹ï¼Œ{username}æ˜¯ä¸€ä¸ª"
    if big_five_scores:
        if big_five_scores.extraversion > 60:
            personality_summary += "å¤–å‘æ´»è·ƒã€"
        elif big_five_scores.extraversion < 40:
            personality_summary += "å†…æ•›æ·±æ€ã€"

        if big_five_scores.openness > 60:
            personality_summary += "å¯Œæœ‰åˆ›é€ åŠ›ã€"

        if big_five_scores.conscientiousness > 60:
            personality_summary += "åšäº‹è®¤çœŸã€"

        if big_five_scores.agreeableness > 60:
            personality_summary += "å‹å–„åˆä½œçš„äººã€‚"
        else:
            personality_summary += "ç‹¬ç«‹è‡ªä¸»çš„äººã€‚"
    else:
        personality_summary += "æœ‰ç‹¬ç‰¹ä¸ªæ€§çš„äººã€‚"

    result = PersonalityAnalysisResult(
        target_userid=target_userid,
        target_username=username,
        analysis_timestamp=int(time.time()),
        message_sample_size=len(messages),
        time_range_start=int(time.time()) - (days * 24 * 60 * 60),
        time_range_end=int(time.time()),
        big_five_scores=big_five_scores,
        mbti_result=mbti_result,
        personality_summary=personality_summary,
        behavior_patterns=behavior_patterns,
        communication_style=communication_style,
        emotional_tendency=emotional_tendency,
        report_markdown="",
    )

    result.report_markdown = generate_markdown_report(result)

    await save_result_to_cache(chat_key, target_userid, result)

    core.logger.info(f"æ€§æ ¼åˆ†æå®Œæˆ: {target_userid}")
    return result.report_markdown


@plugin.mount_sandbox_method(
    SandboxMethodType.TOOL,
    name="è·å–æ€§æ ¼åˆ†ææŠ¥å‘Š",
    description="è·å–å·²ç”Ÿæˆçš„ç”¨æˆ·æ€§æ ¼åˆ†ææŠ¥å‘Š",
)
async def get_personality_report(_ctx: schemas.AgentCtx, chat_key: str, target_userid: str) -> str:
    """Get Personality Report (è·å–æ€§æ ¼åˆ†ææŠ¥å‘Š)

    Get a previously generated personality analysis report from cache.

    Args:
        chat_key (str): Chat channel identifier (use _ck in sandbox)
        target_userid (str): Target user's platform ID

    Returns:
        str: Markdown formatted report or error message

    Example:
        get_personality_report(_ck, "user_12345")
    """
    cached_result = await get_cached_result(chat_key, target_userid)
    if not cached_result:
        raise ValueError(f"Error: No cached personality analysis found for user {target_userid}. Please run analysis first.")

    return cached_result.report_markdown


@plugin.mount_sandbox_method(
    SandboxMethodType.TOOL,
    name="æ¸…é™¤æ€§æ ¼åˆ†æç¼“å­˜",
    description="æ¸…é™¤æŒ‡å®šç”¨æˆ·çš„æ€§æ ¼åˆ†æç¼“å­˜",
)
async def clear_personality_cache(_ctx: schemas.AgentCtx, chat_key: str, target_userid: str) -> str:
    """Clear Personality Cache (æ¸…é™¤æ€§æ ¼åˆ†æç¼“å­˜)

    Clear the cached personality analysis for a specific user.

    Args:
        chat_key (str): Chat channel identifier (use _ck in sandbox)
        target_userid (str): Target user's platform ID

    Returns:
        str: Success message

    Example:
        clear_personality_cache(_ck, "user_12345")
    """
    await clear_cache(chat_key, target_userid)
    return f"Successfully cleared personality analysis cache for user {target_userid}"


# endregion: æ²™ç›’æ–¹æ³•


# region: æç¤ºæ³¨å…¥


@plugin.mount_prompt_inject_method(name="personality_analysis_prompt_inject")
async def personality_analysis_prompt_inject(_ctx: schemas.AgentCtx) -> str:
    """æ€§æ ¼åˆ†ææç¤ºæ³¨å…¥"""
    return """Personality Analysis Plugin Available:
- You can analyze user personality by calling analyze_user_personality tool
- User can request: "åˆ†æXXXçš„æ€§æ ¼" or "ç»™æˆ‘çœ‹çœ‹XXXçš„æ€§æ ¼æŠ¥å‘Š"
- The analysis is based on chat history and includes Big Five and MBTI assessment"""


# endregion: æç¤ºæ³¨å…¥


# region: æ¸…ç†æ–¹æ³•


@plugin.mount_cleanup_method()
async def clean_up():
    """æ¸…ç†æ’ä»¶èµ„æº"""
    core.logger.info("æ€§æ ¼åˆ†ææ’ä»¶æ¸…ç†å®Œæˆ")


# endregion: æ¸…ç†æ–¹æ³•
